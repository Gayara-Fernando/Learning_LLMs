{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e4495b8-4584-4508-aaaf-2710745f106b",
   "metadata": {},
   "source": [
    "This notebook gives a general overview of working with OpenAI with python. The contents follow the informative youtube video by Shaw Talebi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59ce74-61f8-43fa-a8a1-a025f5fec7a1",
   "metadata": {},
   "source": [
    "##### Getting started with OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e0fd08-f7ab-4c97-b4d7-238bb7bd665e",
   "metadata": {},
   "source": [
    "We first need to setup an account at https://openai.com/. Once you have the account, you need an OpenAI access token (A secret key) to access the LLMs by OpenAI. To set up an access toke, use the link here: https://platform.openai.com/settings/organization/api-keys. You need to copy and paste this link at a safe location so that you can use it when you call these LLMs. And since these models are not open-sourced, we also need to set up a payment method inorder to use them. The charge on a per-token basis. The payment method can be set up using the link at https://platform.openai.com/settings/organization/billing/overview and going to add a payment method. The good thing is, you can set up a hard and a soft limit for the amount you want to spend on a monthly basis. The limits can be set here: https://platform.openai.com/settings/organization/limits. Let's run through a few examples Shaw use in his demo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5c3ad-97f1-4b90-a136-deefcb64426e",
   "metadata": {},
   "source": [
    "###### Setting up OpenAPI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e5b11-7eb3-4d1c-afec-c40de019e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d49e0-9167-4c96-94b7-be687e05a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a852c8-b786-4e7c-a832-f12fffe383ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the secret key from openai here to this variable\n",
    "my_sk = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87dade3-5770-40b7-a1d5-76779798a6e2",
   "metadata": {},
   "source": [
    "###### Create a chat completion with openAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4c929-9c03-43f2-97f9-a70bb5a94f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we can use the create method in ChatCompletion module to complete some text (next word prediction). The arguments model specifies which model to access. The messages argument takes as input a list of dictionaries. In the example below, we only have one such dictionary with two keys. The keys \"role\" and \"content\" are prespecified. The role can take the values user, assistant, or system depending on the context. Content is where we specify the text of interest. Since over here we have text completion, the role would be user. The output from this would be acting as the assistant, and give us the next word with the highest probability distribution. \n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e7ddc4-fb10-44fc-9fed-4417881e5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion.to_dict()\n",
    "\n",
    "# The output from this is as below. Note that we need to access the content from the message dictionary for the role assistant.\n",
    "# {'id': 'chatcmpl-7dk1Jkf5SDm2422nYRPL9x0QrlhI4',\n",
    "#  'object': 'chat.completion',\n",
    "#  'created': 1689706049,\n",
    "#  'model': 'gpt-3.5-turbo-0613',\n",
    "#  'choices': [<OpenAIObject at 0x7f9d1a862b80> JSON: {\n",
    "#     \"index\": 0,\n",
    "#     \"message\": {\n",
    "#       \"role\": \"assistant\",\n",
    "#       \"content\": \"heart.\"\n",
    "#     },\n",
    "#     \"finish_reason\": \"stop\"\n",
    "#   }],\n",
    "#  'usage': <OpenAIObject at 0x7f9d1a862c70> JSON: {\n",
    "#    \"prompt_tokens\": 10,\n",
    "#    \"completion_tokens\": 2,\n",
    "#    \"total_tokens\": 12\n",
    "#  }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5a30e-adff-4423-9c2c-0e0c6048bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the chat completion\n",
    "print(chat_completion.choices[0].message.content)\n",
    "\n",
    "# Output: heart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54a5336-8d66-43f7-b5ac-c0a79e7c0576",
   "metadata": {},
   "source": [
    "Let's look at some more arguments in the create method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c517c4-a344-46e8-a617-2c7ad4e6c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max tokens: This can be used to specify how many tokens we need as the output. \n",
    "\n",
    "# create a chat completion\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 1)\n",
    "\n",
    "# print the chat completion\n",
    "print(chat_completion.choices[0].message.content)\n",
    "\n",
    "# Output: heart\n",
    "# Note we do not get the period here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aff859-e4d3-467c-b030-d322738026b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = number of chat completions\n",
    "# create a chat completion\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 2,\n",
    "                                n=5)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)\n",
    "\n",
    "# Output:\n",
    "\n",
    "\n",
    "# heart.\n",
    "# heart and\n",
    "# heart.\n",
    "\n",
    "# heart,\n",
    "\n",
    "# heart,\n",
    "\n",
    "# Note we get two tokens for five times, we also see some next lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a500c5-a53d-4c28-84ff-8115f0a65468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature - This determines if our output should be determinsitic (same thing for n times) or random (different outputs for the n times). This takes values between 0 and 2. If 0, the geerated output will be deterministic. Closer to 2 would be very random. Which number to use will depend on the context of the use.\n",
    "\n",
    "# create a chat completion - for n = 0\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 2,\n",
    "                                n=5,\n",
    "                                temperature=0)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)\n",
    "\n",
    "# Output:\n",
    "\n",
    "# heart.\n",
    "# heart.\n",
    "# heart.\n",
    "# heart.\n",
    "# heart.\n",
    "\n",
    "# create a chat completion for n = 2\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 2,\n",
    "                                n=5,\n",
    "                                temperature=2)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)\n",
    "\n",
    "# Output:\n",
    "\n",
    "# judgment\n",
    "# Advice\n",
    "# .inner awareness\n",
    "# heart.\n",
    "\n",
    "# ging ist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea6e77-6153-4916-9a6a-e13ec1bf62be",
   "metadata": {},
   "source": [
    "##### Building a lyrics completion assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a4b15-79e5-47a8-aada-243b722a35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial prompt with system message and 2 task examples\n",
    "messages_list = [{\"role\":\"system\", \"content\": \"I am Roxette lyric completion assistant. When given a line from a song, I will provide the next line in the song.\"},\n",
    "                 {\"role\":\"user\", \"content\": \"I know there's something in the wake of your smile\"},\n",
    "                 {\"role\":\"assistant\", \"content\": \"I get a notion from the look in your eyes, yeah\"},\n",
    "                 {\"role\":\"user\", \"content\": \"You've built a love but that love falls apart\"},\n",
    "                 {\"role\":\"assistant\", \"content\": \"Your little piece of Heaven turns too dark\"},\n",
    "                 {\"role\":\"user\", \"content\": \"Listen to your\"}]\n",
    "\n",
    "# Notice that the \"system\" role sets the context, and there is a back and forth conversation between the user and the assistant. The chatbot's task is to complete the lyrics. Take a look at the code below. Basically, we are appending the newly generated text, and appending it back to the end of the messages_list dictionary inorder to complete the lyrics. These lyrics are from the popular song Roxette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050dbad-5b83-418a-bf0d-0803728b38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    # create a chat completion\n",
    "    chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", \n",
    "                                    messages=messages_list,\n",
    "                                    max_tokens = 15,\n",
    "                                    n=1,\n",
    "                                    temperature=0)\n",
    "\n",
    "    # print the chat completion\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "\n",
    "    new_message = {\"role\":\"assistant\", \"content\":chat_completion.choices[0].message.content} # append new message to message list\n",
    "    messages_list.append(new_message)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Output:\n",
    "\n",
    "# Heart when he's calling for you\n",
    "# Listen to your heart, there's nothing else you can do\n",
    "# I don't know where you're going and I don't know why\n",
    "# But listen to your heart before you tell him goodbye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad2411-9212-4e5e-b6dd-efae8b6ae099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual lyrics are exactly similar if you google:\n",
    "\n",
    "# Actual lyrics:\n",
    "\n",
    "# Listen to your heart when he's calling for you\n",
    "# Listen to your heart, there's nothing else you can do\n",
    "# I don't know where you're going and I don't know why\n",
    "# But listen to your heart before you tell him goodbye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239a770-ccb7-4462-a388-516ac8105492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the temperature value used is 0. This would mean we need the consistant lyrics as that of the original song. What if we chage the value of this argument to 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4175497b-11a5-4f25-b5fd-43b71c6678f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    # create a chat completion\n",
    "    chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", \n",
    "                                    messages=messages_list,\n",
    "                                    max_tokens = 15,\n",
    "                                    n=1,\n",
    "                                    temperature=2)\n",
    "\n",
    "    # print the chat completion\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "\n",
    "    new_message = {\"role\":\"assistant\", \"content\":chat_completion.choices[0].message.content}\n",
    "    messages_list.append(new_message)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Output:\n",
    "# I reach into the shadows summon Sweet Elaine\n",
    "# ï»¿Pointing all steel values fails if friends remote empty Reply\n",
    "\n",
    "# Image existing\n",
    "# Long seconds confirm flesh pressed secretly Remember saint talk dying To unfamiliar pieces Father blessed\n",
    "# Speech keeps passing shape raises You travel feeling shadows Thriven bodies swept Spirit consume\n",
    "\n",
    "\n",
    "# Notice that now it outputs some gibberish as the lyrics of the song."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_llm_env)",
   "language": "python",
   "name": "tf_llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
